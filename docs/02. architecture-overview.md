# 🏗️ Tackle Box 아키텍처 개요

이 문서는 Tackle Box 프로젝트의 시스템 아키텍처 설계를 위한 개요 문서입니다.  
비즈니스 요구를 기술적 구조로 전환하는 과정을 설명합니다.

---

## 1. 비즈니스 목표 재정의
- 개발자의 기술 역량을 진단하고 시각화할 수 있는 플랫폼 제공
- 반복 진단 및 히스토리 기반 회고 기능으로 성장 방향 제시
- 기술 기반 이력서/포트폴리오 작성의 정량적 근거 제공

<br>

## 2. 품질 속성 정의

| 속성 | 설명 |
|------|------|
| **성능** | 진단 요청의 평균 응답 시간은 300ms 이내여야 함 |
| **확장성** | 진단 항목 및 사용자 수 증가에 따른 수평 확장 가능성 |
| **관측성** | 요청, 오류, 이벤트 추적 가능하며 메트릭 수집 및 시각화 지원 |
| **유지보수성** | 진단 항목의 동적 추가/수정이 가능해야 함 |
| **신뢰성** | 오류 발생 시 데이터 유실 없이 복구 가능해야 함 |
| **보안** | 인증된 사용자만 진단 결과 접근 가능 |
| **배포 유연성** | 로컬/클라우드 환경 모두 단일 배포 명령으로 배포 가능 |
| **모듈성** | 도메인, 진단 로직, 시각화 기능을 분리된 구성으로 설계 |

<br>

## 3. 주요 구성 요소

### 📦 핵심 도메인

- **Skill**: 진단 항목의 정의, 설명, 카테고리 및 버전 정보 포함
- **Evaluation**: 사용자의 진단 응답 결과, 점수, 응답 시간, 저장 시점 등
- **User**: 사용자 식별 정보, 인증 상태, 진단 기록과의 연관

### 🔧 시스템 구성 요소

- **API 서버**: 진단 항목 제공, 응답 처리, 점수 계산
- **Skill Registry 모듈**: 기술 항목 정의 및 버전 관리
- **Evaluation 기록 모듈**: 진단 결과 저장 및 세션 기반 히스토리 관리
- **인증/인가 모듈**: 사용자 로그인/로그아웃 처리, 진단 기록 접근 제어
- **데이터 저장소 (RDB)**: 사용자, 기술 항목, 진단 결과 저장
- **프론트엔드 UI**: 유저 입력 및 진단 결과 시각화 화면
- **시각화 모듈**: 기술 역량 레이더 차트 및 성장 추이 그래프 제공
- **모니터링 시스템**: API 메트릭 수집 및 대시보드 시각화
- **로깅 시스템**: 구조화 로그 수집 및 장애 추적
- **배포 환경**: 로컬 및 클라우드 대응을 위한 Docker 기반 구성

<br>

## 4. 예상 시스템 흐름 시나리오

1. 사용자가 로그인하여 인증을 완료한다.
2. 진단 페이지에 접속한다.
2. 진단 항목 리스트를 조회한다 (Skill API).
3. 각 항목에 대해 사용자가 응답을 제출한다.
4. 서버에서 점수를 계산하고 결과를 저장한다.
5. 결과는 히스토리에 반영되며 시각화용 데이터로 가공된다.
6. 사용자는 지난 결과와 비교하거나 회고 화면을 확인한다.

<br>

## 5. C4 모델 기반 설계

### 🔹 Level 1: Context Diagram
> 시스템이 외부 세계와 어떻게 연결되어 있는지 (사용자, 외부 시스템)
```
[사용자] 

   ↕

[Tackle Box 시스템]

   ↕

(외부 인증 서비스를 사용할 경우)
[외부 인증 시스템]
```
- 사용자는 진단 기능, 시각화, 히스토리 조회 기능을 사용한다.
- 시스템은 인증된 사용자만 결과에 접근할 수 있도록 제한한다.

### 🔹 Level 2: Container Diagram
> 시스템 내부 구성 요소 간 구조 (애플리케이션 / 서비스 / DB 단위)
```
[브라우저]

   ↓

[프론트엔드 UI]
 - 사용자 입력 및 진단 결과 시각화 화면 제공

   ↓

[API 서버]
 - 진단 API, 사용자 인증, 결과 저장 처리

   ↕

[데이터 저장소 (RDB)]
 - 사용자, 진단 항목, 결과 데이터 저장

------------------------------------

[API 서버]
 - 로그/메트릭 전송

   ↓              ↘

[로깅 시스템]   [모니터링 시스템]
 
 - 로그 예: 요청 정보, 오류, 이벤트 기록
 - 메트릭 예: 응답 시간, 처리량, 에러율 등 운영 지표
```

#### 🔍 구조 및 흐름 설명

- **프론트엔드 UI**는 사용자와 직접 상호작용하며, 입력된 정보를 API 서버에 전달하고 결과를 시각화함
- **API 서버**는 사용자 인증, 진단 항목 제공, 응답 처리, 점수 계산, 결과 저장 등 핵심 로직을 담당함
- **데이터 저장소 (RDB)**는 모든 사용자 정보, 진단 항목, 결과 데이터를 영속적으로 저장함
- **로깅/모니터링 시스템**은 API 서버에서 전송한 로그 및 메트릭 데이터를 수집하여 시각화하거나 장애 탐지에 활용됨

<br>

## 6. 품질 속성 기반 기술 적용 방향

아래는 현재 시스템 설계에서 정의한 주요 품질 속성을 기준으로,  
이 속성들을 실현하기 위한 기술적 방향성을 간략히 정리한 것이다.  

구체적인 기술 후보군 비교 및 최종 기술 결정 과정은 `tech-decisions.md` 문서에서 다룬다.

### 📐 품질 속성별 고려 방향

- **관측성**  
  - 메트릭 수집, 로그 수집, 대시보드 시각화 등 운영 지표 확보가 필요함  
  - 예시 도구: Prometheus, Grafana, Loki 등

- **성능 / 확장성**  
  - 진단 항목 수 및 사용자 수 증가를 고려해 데이터베이스 성능, 캐시 도입 여부 등을 판단  
  - 예시: PostgreSQL, Redis 등

- **유지보수성**  
  - 진단 항목 / 로직 / 시각화 모듈을 각기 분리하여 기능별로 관리 가능하게 설계  
  - 진단 항목은 버전 관리 구조를 포함해야 함

- **보안**  
  - 인증되지 않은 사용자의 진단 결과 접근 제한  
  - 세션 관리 또는 JWT 기반 인증 고려

- **배포 유연성**  
  - 로컬 및 클라우드 환경 모두에서 실행 가능한 경량화된 배포 구조 필요  
  - 예시: Docker 기반 컨테이너 구성

- **신뢰성**  
  - 장애 또는 오류 발생 시에도 데이터 손실 없이 안정적으로 복구 가능한 구조 필요  
  - 예시: 트랜잭션 기반 저장, 정기 백업 및 장애 복구 전략 포함

- **모듈성**  
  - 시스템은 진단 로직, 시각화, 기록 관리 등의 기능 단위로 명확히 분리되어야 하며  
    각 모듈은 독립적으로 변경, 테스트, 배포 가능해야 함

<br>

## 7. 아키텍처 설계 원칙 요약

- **모듈화와 명확한 책임 분리**: 각 도메인별 경계 유지
- **관측 가능성은 설계 단계에서 포함**: 로깅/메트릭/에러 추적 내장